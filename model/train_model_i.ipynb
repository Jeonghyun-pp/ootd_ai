{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW4f5xntei6e",
        "outputId": "fa4858bc-66f7-4e85-dda6-8b18353963b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip -q uninstall -y torch torchtext torchaudio torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip -q install --no-cache-dir torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "wZzmDT7Ae_jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import json\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Iterable, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7btn6u7Ze1X2",
        "outputId": "8d1d81e4-0303-49d4-8cf1-5a6380b2cd9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.5.1+cu121\n",
            "cuda available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    seed: int = 42\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # text encoder\n",
        "    max_len: int = 32\n",
        "    text_emb_dim: int = 128\n",
        "    text_hidden_dim: int = 256\n",
        "\n",
        "    # item encoder\n",
        "    cat_emb_dim: int = 32\n",
        "    item_hidden_dim: int = 256\n",
        "\n",
        "    # shared embedding dim\n",
        "    embed_dim: int = 256\n",
        "\n",
        "    # contrastive\n",
        "    temperature: float = 0.12\n",
        "\n",
        "    # training\n",
        "    batch_size: int = 256     # 배치 내 item_id 중복 금지 조건에서의 \"유니크 아이템 수\"\n",
        "    num_epochs: int = 3\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    grad_clip: float = 1.0\n",
        "    log_every: int = 100\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "cfg.text_use_attn = True\n",
        "cfg.text_attn_nhead = 4\n",
        "cfg.text_attn_ff = 256\n",
        "\n",
        "set_seed(cfg.seed)\n",
        "print(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bZDHwn9f1sa",
        "outputId": "6a960160-2e4e-4b2b-e530-d36f3d57a0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(seed=42, device='cuda', max_len=32, text_emb_dim=128, text_hidden_dim=256, cat_emb_dim=32, item_hidden_dim=256, embed_dim=256, temperature=0.12, batch_size=256, num_epochs=3, lr=0.0003, weight_decay=0.0001, grad_clip=1.0, log_every=100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Weather label -> temperature range (°C)\n",
        "# -----------------------------\n",
        "# \"적당히 한국인의 정서\" 기준으로 만든 규칙표 (과학적 절대값이 아니라 운영 규칙)\n",
        "WEATHER_LABEL_TO_TEMP_RANGE: Dict[str, Tuple[int, int]] = {\n",
        "    \"한파\":   (-99, -15),\n",
        "    \"한겨울\": (-14,   3),\n",
        "    \"쌀쌀\":   ( 4,  11),\n",
        "    \"선선\":   (12,  18),\n",
        "    \"따뜻\":   (19,  27),\n",
        "    \"더움\":   (28,  35),\n",
        "    \"폭염\":   (36,  99),\n",
        "}\n",
        "\n",
        "# 사용자가 날씨 라벨 대신 직접 범위를 바꾸고 싶으면 여기만 수정하면 전체 파이프라인이 유지됩니다.\n",
        "\n",
        "def parse_temperature_to_int(temp_text: str) -> int:\n",
        "    \"\"\"\n",
        "    날씨 API에서 들어오는 '기온 텍스트'를 정수(°C)로 변환.\n",
        "    예시 처리:\n",
        "      - \"8\", \"8도\", \"8°C\", \"8 C\"\n",
        "      - \"영하 3도\", \"-3도\", \"-3°C\"\n",
        "      - \"영상 2도\"\n",
        "    규칙:\n",
        "      - 가장 먼저 발견되는 숫자를 사용\n",
        "      - 영하/마이너스는 음수 처리\n",
        "      - 소수면 반올림(0.5 이상 올림)\n",
        "    \"\"\"\n",
        "    if temp_text is None:\n",
        "        raise ValueError(\"temp_text is None\")\n",
        "\n",
        "    s = str(temp_text).strip().lower()\n",
        "    if len(s) == 0:\n",
        "        raise ValueError(\"temp_text is empty\")\n",
        "\n",
        "    # 음수 표기 감지\n",
        "    negative = False\n",
        "    if \"영하\" in s or s.startswith(\"-\"):\n",
        "        negative = True\n",
        "\n",
        "    # 숫자(정수/소수) 추출\n",
        "    import re\n",
        "    m = re.search(r\"(-?\\d+(\\.\\d+)?)\", s)\n",
        "    if not m:\n",
        "        raise ValueError(f\"cannot parse temperature from: {temp_text}\")\n",
        "\n",
        "    val = float(m.group(1))\n",
        "    # \"영하 3도\"에서 숫자가 3으로 잡히는 경우 보정\n",
        "    if negative and val > 0:\n",
        "        val = -val\n",
        "\n",
        "    # 반올림해서 int로\n",
        "    return int(round(val))\n",
        "\n",
        "print(\"Weather mapping table:\", WEATHER_LABEL_TO_TEMP_RANGE)\n",
        "print(\"Temp parser test:\", parse_temperature_to_int(\"영하 3도\"), parse_temperature_to_int(\"8.4°C\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVgwaYxbf6Dt",
        "outputId": "8f3deeb9-2b20-4e69-cf69-4b0e1d750c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather mapping table: {'한파': (-99, -15), '한겨울': (-14, 3), '쌀쌀': (4, 11), '선선': (12, 18), '따뜻': (19, 27), '더움': (28, 35), '폭염': (36, 99)}\n",
            "Temp parser test: -3 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"/content/drive/MyDrive/Colab Notebooks/학회 신기플/kfashion_train_label_filled_utf8sig_plus678.csv\"\n",
        "VAL_PATH   = \"/content/drive/MyDrive/Colab Notebooks/학회 신기플/kfashion_val_filled_utf8sig_plus345678.csv\"\n",
        "TEST_PATH  = \"/content/drive/MyDrive/Colab Notebooks/학회 신기플/kfashion_test_filled_utf8sig_plus345678.csv\"\n",
        "\n",
        "df_train = pd.read_csv(TRAIN_PATH)\n",
        "df_val   = pd.read_csv(VAL_PATH)\n",
        "df_test  = pd.read_csv(TEST_PATH)\n",
        "\n",
        "print(\"train:\", df_train.shape, \"val:\", df_val.shape, \"test:\", df_test.shape)\n",
        "print(\"columns:\", df_train.columns.tolist())\n",
        "print(\"weather labels(train):\", sorted(df_train[\"날씨\"].dropna().unique().tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME8CiVwRgL_G",
        "outputId": "991175cb-695d-4e23-ffa4-e3dc96bb290e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: (127002, 21) val: (85407, 107) test: (85408, 107)\n",
            "columns: ['image_name', 'image_id', 'part', '카테고리', '색상', '서브색상', '소매기장', '기장', '핏', '옷깃', '스타일', '서브스타일', '날씨', '구체적인 상황 1', '구체적인 상황 2', '구체적인 상황 3', '핵심키워드 4', '핵심키워드 5', '구체적인 상황 6', '구체적인 상황 7', '구체적인 상황 8']\n",
            "weather labels(train): ['더움', '따뜻', '선선', '쌀쌀', '폭염', '한겨울', '한파']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 1) 입력 피처 정의 (스타일 제외)\n",
        "# -----------------------------\n",
        "ID_COL = \"image_id\"\n",
        "\n",
        "FEATURE_COLS = [\n",
        "    \"part\", \"카테고리\", \"색상\", \"서브색상\", \"소매기장\", \"기장\", \"핏\", \"옷깃\",\n",
        "    # \"스타일\",  # <-- 제외 (데이터 누수 방지)\n",
        "    \"서브스타일\",\n",
        "    \"날씨\",     # 라벨 자체도 피처로 쓰는 건 가능(사용자 요구에서 제외 요청 없음)\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# 2) 정답 텍스트 컬럼: 상황 1~8(데이터상 실제 존재는 1,2,3,6,7,8)\n",
        "# -----------------------------\n",
        "SITU_COLS = [\"구체적인 상황 1\", \"구체적인 상황 2\", \"구체적인 상황 3\",\n",
        "             \"구체적인 상황 6\", \"구체적인 상황 7\", \"구체적인 상황 8\"]\n",
        "\n",
        "# (선택 옵션) 핵심키워드까지 포함하고 싶으면 True로\n",
        "USE_CORE_KEYWORDS = True\n",
        "CORE_KEYWORD_COLS = [\"핵심키워드 4\", \"핵심키워드 5\"]\n",
        "\n",
        "TEXT_COLS = SITU_COLS + (CORE_KEYWORD_COLS if USE_CORE_KEYWORDS else [])\n",
        "\n",
        "# -----------------------------\n",
        "# 3) item_table + pairs 생성 (train 기준)\n",
        "#    item_table에 temp_range(정수)도 추가\n",
        "# -----------------------------\n",
        "def build_item_table_and_pairs(df: pd.DataFrame) -> Tuple[Dict[str, dict], List[dict]]:\n",
        "    item_table: Dict[str, dict] = {}\n",
        "    pairs: List[dict] = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        iid = str(row[ID_COL])\n",
        "\n",
        "        # item_table 구성 (아이템당 1회만)\n",
        "        if iid not in item_table:\n",
        "            it = {}\n",
        "            for c in FEATURE_COLS:\n",
        "                v = row.get(c, None)\n",
        "                it[c] = None if (pd.isna(v)) else str(v)\n",
        "\n",
        "            # temp_range 생성: 날씨 라벨 -> 구간\n",
        "            wlabel = it.get(\"날씨\", None)\n",
        "            if wlabel not in WEATHER_LABEL_TO_TEMP_RANGE:\n",
        "                # 데이터에 없는 라벨이면 일단 매우 넓게 (운영 중엔 라벨 정합성을 맞추는 게 정상)\n",
        "                it[\"temp_range\"] = (-50, 50)\n",
        "            else:\n",
        "                it[\"temp_range\"] = WEATHER_LABEL_TO_TEMP_RANGE[wlabel]\n",
        "\n",
        "            item_table[iid] = it\n",
        "\n",
        "        # pairs 구성 (상황 텍스트 1~8)\n",
        "        for col in TEXT_COLS:\n",
        "            txt = row.get(col, \"\")\n",
        "            if isinstance(txt, str) and txt.strip():\n",
        "                t = txt.strip()\n",
        "                # 길이 제한(요구사항이 원래 생성 규칙에 있었지만, 데이터에도 혹시 이상치 있으면 방어)\n",
        "                if 3 <= len(t) <= 32:\n",
        "                    pairs.append({\"item_id\": iid, \"text\": t})\n",
        "                else:\n",
        "                    # 길이 범위를 벗어나면 제외 (학습 분포 안정)\n",
        "                    continue\n",
        "\n",
        "    return item_table, pairs\n",
        "\n",
        "item_table, pairs = build_item_table_and_pairs(df_train)\n",
        "\n",
        "print(\"items:\", len(item_table))\n",
        "print(\"pairs:\", len(pairs))\n",
        "print(\"sample item:\", list(item_table.items())[:1])\n",
        "print(\"sample pairs:\", pairs[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dub407_jgjZh",
        "outputId": "580e0a57-cabe-4e31-d7a5-f3249c179562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "items: 85268\n",
            "pairs: 1016016\n",
            "sample item: [('37573', {'part': '상의', '카테고리': '니트웨어', '색상': '베이지', '서브색상': '없음', '소매기장': '긴팔', '기장': '없음', '핏': '노멀', '옷깃': '없음', '서브스타일': '컨트리', '날씨': '쌀쌀', 'temp_range': (4, 11)})]\n",
            "sample pairs: [{'item_id': '37573', 'text': '베이지 긴팔 로맨틱'}, {'item_id': '37573', 'text': '쌀쌀 날 노멀 핏 없음 연출'}, {'item_id': '37573', 'text': '컨트리 무드 베이지 포인트'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "class SimpleVocab:\n",
        "    \"\"\"\n",
        "    torchtext.vocab.Vocab과 비슷한 인터페이스만 흉내낸 최소 구현\n",
        "    (get_stoi / get_itos 제공)\n",
        "    \"\"\"\n",
        "    def __init__(self, itos: list[str], stoi: dict[str, int]):\n",
        "        self._itos = itos\n",
        "        self._stoi = stoi\n",
        "\n",
        "    def get_itos(self):\n",
        "        return self._itos\n",
        "\n",
        "    def get_stoi(self):\n",
        "        return self._stoi\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._itos)\n",
        "\n",
        "class TextVocab:\n",
        "    def __init__(self, vocab, pad_idx: int, unk_idx: int, tokenizer):\n",
        "        self.vocab = vocab\n",
        "        self.pad_idx = pad_idx\n",
        "        self.unk_idx = unk_idx\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def encode(self, text: str, max_len: int):\n",
        "        tokens = self.tokenizer(text)\n",
        "        stoi = self.vocab.get_stoi()\n",
        "        ids = [stoi.get(t, self.unk_idx) for t in tokens][:max_len]\n",
        "        attn = [1] * len(ids)\n",
        "        if len(ids) < max_len:\n",
        "            pad_len = max_len - len(ids)\n",
        "            ids += [self.pad_idx] * pad_len\n",
        "            attn += [0] * pad_len\n",
        "        return torch.tensor(ids, dtype=torch.long), torch.tensor(attn, dtype=torch.long)\n",
        "\n",
        "def build_text_vocab(texts, min_freq: int = 1) -> TextVocab:\n",
        "    tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "    counter = Counter()\n",
        "    for t in texts:\n",
        "        counter.update(tokenizer(t))\n",
        "\n",
        "    # specials 고정: pad=0, unk=1\n",
        "    itos = [\"<pad>\", \"<unk>\"]\n",
        "    # min_freq 이상인 토큰만 추가 (빈도 내림차순 -> 토큰명 정렬로 tie break)\n",
        "    tokens = [tok for tok, c in counter.items() if c >= min_freq]\n",
        "    tokens.sort(key=lambda x: (-counter[x], x))\n",
        "\n",
        "    itos.extend(tokens)\n",
        "    stoi = {tok: i for i, tok in enumerate(itos)}\n",
        "\n",
        "    vocab = SimpleVocab(itos=itos, stoi=stoi)\n",
        "    return TextVocab(vocab=vocab, pad_idx=stoi[\"<pad>\"], unk_idx=stoi[\"<unk>\"], tokenizer=tokenizer)\n",
        "\n",
        "# 사용\n",
        "text_vocab = build_text_vocab([r[\"text\"] for r in pairs], min_freq=1)\n",
        "print(\"vocab size:\", len(text_vocab.vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHYeub0NhXmK",
        "outputId": "3ffecdc0-93f5-4ba8-cd76-b328a8f9683d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_maps_from_item_table(item_table: Dict[str, dict], feature_cols: List[str]) -> Dict[str, Dict[str, int]]:\n",
        "    maps = {}\n",
        "    for col in feature_cols:\n",
        "        vals = set()\n",
        "        for it in item_table.values():\n",
        "            v = it.get(col, None)\n",
        "            if v is None:\n",
        "                continue\n",
        "            vals.add(str(v))\n",
        "        vocab = {\"<unk>\": 0}\n",
        "        for v in sorted(vals):\n",
        "            vocab[v] = len(vocab)\n",
        "        maps[col] = vocab\n",
        "    return maps\n",
        "\n",
        "maps = build_maps_from_item_table(item_table, FEATURE_COLS)\n",
        "print({c: len(maps[c]) for c in maps})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps9tbVEIgxZa",
        "outputId": "af88fc16-3f81-4479-b16e-73c9f857f11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'part': 5, '카테고리': 22, '색상': 23, '서브색상': 23, '소매기장': 7, '기장': 12, '핏': 9, '옷깃': 11, '서브스타일': 25, '날씨': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PairDataset(Dataset):\n",
        "    def __init__(self, pairs, item_table, text_vocab, cfg, maps, feature_cols):\n",
        "        self.pairs = pairs\n",
        "        self.item_table = item_table\n",
        "        self.text_vocab = text_vocab\n",
        "        self.cfg = cfg\n",
        "        self.maps = maps\n",
        "        self.feature_cols = feature_cols\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.pairs[idx]\n",
        "        item_id = row[\"item_id\"]\n",
        "        text = row[\"text\"]\n",
        "\n",
        "        input_ids, attn = self.text_vocab.encode(text, self.cfg.max_len)\n",
        "        item = self.item_table[item_id]\n",
        "\n",
        "        feats = {}\n",
        "        for col in self.feature_cols:\n",
        "            m = self.maps[col]\n",
        "            v = item.get(col, None)\n",
        "            v = \"<unk>\" if (v is None) else str(v)\n",
        "            feats[col] = torch.tensor(m.get(v, 0), dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            \"item_id\": item_id,\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attn,\n",
        "            \"feats\": feats\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.stack([b[\"input_ids\"] for b in batch], dim=0)\n",
        "    attn = torch.stack([b[\"attention_mask\"] for b in batch], dim=0)\n",
        "    item_ids = [b[\"item_id\"] for b in batch]\n",
        "\n",
        "    feat_keys = batch[0][\"feats\"].keys()\n",
        "    feats = {k: torch.stack([b[\"feats\"][k] for b in batch], dim=0) for k in feat_keys}\n",
        "\n",
        "    return {\"item_ids\": item_ids, \"input_ids\": input_ids, \"attention_mask\": attn, \"feats\": feats}\n",
        "\n",
        "print(\"Dataset ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQGnF3P4g1s-",
        "outputId": "e0b6f8bc-646f-4755-f1ae-1e0b00b4afcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random\n",
        "from torch.utils.data import Sampler\n",
        "\n",
        "class StyleFirstSubstyleSecondUniqueSampler(Sampler):\n",
        "    \"\"\"\n",
        "    배치 내 item_id 중복을 '절대' 허용하지 않으며,\n",
        "    스타일을 1순위로 다양화하고, 스타일 내부에서 서브스타일을 2순위로 다양화한다.\n",
        "\n",
        "    - style_key 우선\n",
        "    - substyle_key는 같은 style 내에서 라운드로빈으로 분산\n",
        "    - 배치가 부족하면 제약을 완화해서 채우되, 중복은 절대 없음\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pairs,\n",
        "        item_table,\n",
        "        batch_size,\n",
        "        style_key=\"스타일\",\n",
        "        substyle_key=\"서브스타일\",\n",
        "        drop_last=True,\n",
        "        shuffle=True,\n",
        "        max_per_style_in_batch=None,        # 기본: batch_size//16\n",
        "        max_per_none_style_in_batch=8,      # style이 없거나 '없음' 계열인 경우 cap\n",
        "        none_tokens=(\"없음\", \"None\", \"nan\", \"NaN\", \"\"),\n",
        "    ):\n",
        "        self.pairs = pairs\n",
        "        self.item_table = item_table\n",
        "        self.batch_size = int(batch_size)\n",
        "        self.drop_last = drop_last\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        self.style_key = style_key\n",
        "        self.substyle_key = substyle_key\n",
        "\n",
        "        self.none_tokens = set(map(str, none_tokens))\n",
        "\n",
        "        if max_per_style_in_batch is None:\n",
        "            self.max_per_style_in_batch = max(4, self.batch_size // 16)  # 256이면 16\n",
        "        else:\n",
        "            self.max_per_style_in_batch = int(max_per_style_in_batch)\n",
        "\n",
        "        self.max_per_none_style_in_batch = int(max_per_none_style_in_batch)\n",
        "\n",
        "        # item_id -> pair indices\n",
        "        self.item_to_indices = {}\n",
        "        for i, r in enumerate(pairs):\n",
        "            self.item_to_indices.setdefault(r[\"item_id\"], []).append(i)\n",
        "        self.items = list(self.item_to_indices.keys())\n",
        "\n",
        "        def norm_label(x):\n",
        "            if x is None:\n",
        "                return \"<none>\"\n",
        "            s = str(x).strip()\n",
        "            if s in self.none_tokens:\n",
        "                return \"<none>\"\n",
        "            return s\n",
        "\n",
        "        # style/substyle per item\n",
        "        self.item_style = {}\n",
        "        self.item_substyle = {}\n",
        "        for iid in self.items:\n",
        "            it = item_table.get(iid, {})\n",
        "            self.item_style[iid] = norm_label(it.get(style_key, None))\n",
        "            self.item_substyle[iid] = norm_label(it.get(substyle_key, None))\n",
        "\n",
        "        # style -> substyle -> [items]\n",
        "        self.style_sub_items = {}\n",
        "        for iid in self.items:\n",
        "            st = self.item_style[iid]\n",
        "            sb = self.item_substyle[iid]\n",
        "            self.style_sub_items.setdefault(st, {}).setdefault(sb, []).append(iid)\n",
        "\n",
        "        self.styles = list(self.style_sub_items.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        n = len(self.items)\n",
        "        return (n // self.batch_size) if self.drop_last else math.ceil(n / self.batch_size)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # 에폭마다 \"아이템은 1번만 쓰자\"에 가까운 동작을 위해,\n",
        "        # style/substyle 리스트를 셔플하고 포인터로 소진하는 방식 사용\n",
        "        styles = self.styles[:]\n",
        "        if self.shuffle:\n",
        "            random.shuffle(styles)\n",
        "\n",
        "        # style별 substyle 목록 셔플 + 각 substyle의 item 목록 셔플\n",
        "        style_to_subs = {}\n",
        "        for st in styles:\n",
        "            submap = self.style_sub_items[st]\n",
        "            subs = list(submap.keys())\n",
        "            if self.shuffle:\n",
        "                random.shuffle(subs)\n",
        "                for sb in subs:\n",
        "                    random.shuffle(submap[sb])\n",
        "            style_to_subs[st] = subs\n",
        "\n",
        "        # 포인터들\n",
        "        ptr_item = {(st, sb): 0 for st in styles for sb in style_to_subs[st]}\n",
        "        ptr_sub = {st: 0 for st in styles}\n",
        "\n",
        "        # 남은 아이템이 있는지\n",
        "        def has_remaining(st):\n",
        "            submap = self.style_sub_items[st]\n",
        "            for sb in style_to_subs[st]:\n",
        "                if ptr_item[(st, sb)] < len(submap[sb]):\n",
        "                    return True\n",
        "            return False\n",
        "\n",
        "        # style에서 하나 꺼내기: substyle 라운드로빈\n",
        "        def pop_one(st):\n",
        "            subs = style_to_subs[st]\n",
        "            if not subs:\n",
        "                return None\n",
        "            submap = self.style_sub_items[st]\n",
        "            for _ in range(len(subs)):\n",
        "                j = ptr_sub[st] % len(subs)\n",
        "                sb = subs[j]\n",
        "                ptr_sub[st] = (ptr_sub[st] + 1) % len(subs)\n",
        "                k = ptr_item[(st, sb)]\n",
        "                if k < len(submap[sb]):\n",
        "                    iid = submap[sb][k]\n",
        "                    ptr_item[(st, sb)] += 1\n",
        "                    return iid\n",
        "            return None\n",
        "\n",
        "        # 배치 구성\n",
        "        batch = []\n",
        "        used_items = set()\n",
        "        style_count = {}\n",
        "\n",
        "        # PASS1: 스타일 cap을 지키며 채우기\n",
        "        while True:\n",
        "            progressed = False\n",
        "            if self.shuffle:\n",
        "                random.shuffle(styles)\n",
        "\n",
        "            for st in styles:\n",
        "                if len(batch) >= self.batch_size:\n",
        "                    break\n",
        "                if not has_remaining(st):\n",
        "                    continue\n",
        "\n",
        "                cap = self.max_per_none_style_in_batch if st == \"<none>\" else self.max_per_style_in_batch\n",
        "                if style_count.get(st, 0) >= cap:\n",
        "                    continue\n",
        "\n",
        "                iid = pop_one(st)\n",
        "                if iid is None:\n",
        "                    continue\n",
        "                if iid in used_items:\n",
        "                    continue  # ✅ 배치 내 중복 절대 금지\n",
        "\n",
        "                idx = random.choice(self.item_to_indices[iid])\n",
        "                batch.append(idx)\n",
        "                used_items.add(iid)\n",
        "                style_count[st] = style_count.get(st, 0) + 1\n",
        "                progressed = True\n",
        "\n",
        "            if len(batch) == self.batch_size:\n",
        "                yield batch\n",
        "                batch, used_items, style_count = [], set(), {}\n",
        "                continue\n",
        "\n",
        "            # PASS2: 제약 완화(스타일 cap 무시)해서 \"남아 있는 것\" 중에서 채우기\n",
        "            # 단, 여전히 배치 내 item_id 중복은 금지\n",
        "            if len(batch) < self.batch_size:\n",
        "                # 남은 후보를 한 번 훑어서 채움 (비용 줄이려면 스타일 순회)\n",
        "                for st in styles:\n",
        "                    if len(batch) >= self.batch_size:\n",
        "                        break\n",
        "                    while has_remaining(st) and len(batch) < self.batch_size:\n",
        "                        iid = pop_one(st)\n",
        "                        if iid is None:\n",
        "                            break\n",
        "                        if iid in used_items:\n",
        "                            continue\n",
        "                        idx = random.choice(self.item_to_indices[iid])\n",
        "                        batch.append(idx)\n",
        "                        used_items.add(iid)\n",
        "                        progressed = True\n",
        "\n",
        "            if len(batch) == self.batch_size:\n",
        "                yield batch\n",
        "                batch, used_items, style_count = [], set(), {}\n",
        "                continue\n",
        "\n",
        "            if not progressed:\n",
        "                break\n",
        "\n",
        "        if len(batch) > 0 and not self.drop_last:\n",
        "            yield batch"
      ],
      "metadata": {
        "id": "XM9AbzuAg4Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, out_dim, pad_idx,\n",
        "                 use_attn=False, nhead=4, ff_dim=256):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
        "        self.use_attn = use_attn\n",
        "        if use_attn:\n",
        "            layer = nn.TransformerEncoderLayer(\n",
        "                d_model=emb_dim, nhead=nhead, dim_feedforward=ff_dim, batch_first=True\n",
        "            )\n",
        "            self.attn = nn.TransformerEncoder(layer, num_layers=1)\n",
        "        else:\n",
        "            self.attn = None\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(emb_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.emb(input_ids)\n",
        "        if self.use_attn:\n",
        "            key_padding_mask = (attention_mask == 0)\n",
        "            x = self.attn(x, src_key_padding_mask=key_padding_mask)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        x = x * mask\n",
        "        denom = mask.sum(dim=1).clamp_min(1.0)\n",
        "        pooled = x.sum(dim=1) / denom\n",
        "        z = self.mlp(pooled)\n",
        "        return F.normalize(z, dim=-1)\n",
        "\n",
        "\n",
        "class ItemEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    FEATURE_COLS의 각 컬럼을 embedding -> concat -> MLP\n",
        "    \"\"\"\n",
        "    def __init__(self, maps, feature_cols, emb_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.feature_cols = feature_cols\n",
        "        self.embs = nn.ModuleDict({col: nn.Embedding(len(maps[col]), emb_dim) for col in feature_cols})\n",
        "\n",
        "        in_dim = emb_dim * len(feature_cols)\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, feats):\n",
        "        vecs = []\n",
        "        for col in self.feature_cols:\n",
        "            vecs.append(self.embs[col](feats[col]))  # (B,emb)\n",
        "        x = torch.cat(vecs, dim=1)\n",
        "        z = self.proj(x)\n",
        "        return F.normalize(z, dim=-1)\n",
        "\n",
        "\n",
        "def contrastive_loss(z_text: torch.Tensor, z_item: torch.Tensor, temperature: float) -> torch.Tensor:\n",
        "    logits = (z_text @ z_item.T) / temperature\n",
        "    targets = torch.arange(logits.size(0), device=logits.device)\n",
        "    loss_t2i = F.cross_entropy(logits, targets)\n",
        "    loss_i2t = F.cross_entropy(logits.T, targets)\n",
        "    return 0.5 * (loss_t2i + loss_i2t)\n",
        "\n",
        "print(\"Models & loss ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYroDZeAhe4y",
        "outputId": "1f66d04c-a685-40cf-9821-403447e6bcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models & loss ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(text_enc: nn.Module, item_enc: nn.Module, loader: DataLoader, opt, cfg: Config):\n",
        "    text_enc.train(); item_enc.train()\n",
        "    total = 0.0\n",
        "\n",
        "    for step, batch in enumerate(loader):\n",
        "        input_ids = batch[\"input_ids\"].to(cfg.device)\n",
        "        attn = batch[\"attention_mask\"].to(cfg.device)\n",
        "        feats = {k: v.to(cfg.device) for k, v in batch[\"feats\"].items()}\n",
        "\n",
        "        zt = text_enc(input_ids, attn)\n",
        "        zi = item_enc(feats)\n",
        "        loss = contrastive_loss(zt, zi, cfg.temperature)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        if cfg.grad_clip is not None:\n",
        "            nn.utils.clip_grad_norm_(list(text_enc.parameters()) + list(item_enc.parameters()), cfg.grad_clip)\n",
        "        opt.step()\n",
        "\n",
        "        total += float(loss.item())\n",
        "        if (step + 1) % cfg.log_every == 0:\n",
        "            print(f\"[train] step {step+1}/{len(loader)} loss={total/(step+1):.4f}\")\n",
        "\n",
        "    return total / max(1, len(loader))\n",
        "\n",
        "print(\"Train loop ready.\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_inbatch_metrics(text_enc, item_enc, loader, cfg, max_batches=50):\n",
        "    text_enc.eval(); item_enc.eval()\n",
        "    acc1_list = []\n",
        "    pos_list = []\n",
        "    negmax_list = []\n",
        "    margin_list = []\n",
        "\n",
        "    for b, batch in enumerate(loader):\n",
        "        if b >= max_batches:\n",
        "            break\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(cfg.device)\n",
        "        attn = batch[\"attention_mask\"].to(cfg.device)\n",
        "        feats = {k: v.to(cfg.device) for k, v in batch[\"feats\"].items()}\n",
        "\n",
        "        zt = text_enc(input_ids, attn)\n",
        "        zi = item_enc(feats)\n",
        "\n",
        "        sims = (zt @ zi.T)  # (B,B)\n",
        "        B = sims.size(0)\n",
        "        targets = torch.arange(B, device=sims.device)\n",
        "\n",
        "        # top1 acc\n",
        "        pred = sims.argmax(dim=1)\n",
        "        acc1 = (pred == targets).float().mean().item()\n",
        "        acc1_list.append(acc1)\n",
        "\n",
        "        # pos, negmax, margin\n",
        "        pos = sims[targets, targets]\n",
        "        sims_masked = sims.clone()\n",
        "        sims_masked[targets, targets] = -1e9\n",
        "        negmax = sims_masked.max(dim=1).values\n",
        "\n",
        "        pos_list.append(pos.mean().item())\n",
        "        negmax_list.append(negmax.mean().item())\n",
        "        margin_list.append((pos - negmax).mean().item())\n",
        "\n",
        "    return {\n",
        "        \"acc1\": float(np.mean(acc1_list)),\n",
        "        \"pos_mean\": float(np.mean(pos_list)),\n",
        "        \"negmax_mean\": float(np.mean(negmax_list)),\n",
        "        \"margin_mean\": float(np.mean(margin_list)),\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwaNJSPJhgSg",
        "outputId": "ad6dc381-0964-4607-eb77-9c856b388c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loop ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- val item_table / pairs 생성 ---\n",
        "val_item_table, val_pairs = build_item_table_and_pairs(df_val)\n",
        "\n",
        "# (중요) train vocab을 그대로 쓰는 게 일반적 (val로 vocab 확장하면 누수/불안정)\n",
        "# text_vocab 그대로 사용\n",
        "\n",
        "val_ds = PairDataset(val_pairs, val_item_table, text_vocab, cfg, maps, FEATURE_COLS)\n",
        "print(\"val items:\", len(val_item_table), \"val pairs:\", len(val_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXZk5z5tjvKl",
        "outputId": "64b6113b-d189-453f-bb74-3579ba2693cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val items: 79804 val pairs: 683256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_one_epoch(text_enc, item_enc, loader, cfg, max_batches=50):\n",
        "    text_enc.eval(); item_enc.eval()\n",
        "    total_loss = 0.0\n",
        "    acc1_list = []\n",
        "    margin_list = []\n",
        "\n",
        "    for b, batch in enumerate(loader):\n",
        "        if b >= max_batches:\n",
        "            break\n",
        "        input_ids = batch[\"input_ids\"].to(cfg.device)\n",
        "        attn = batch[\"attention_mask\"].to(cfg.device)\n",
        "        feats = {k: v.to(cfg.device) for k, v in batch[\"feats\"].items()}\n",
        "\n",
        "        zt = text_enc(input_ids, attn)\n",
        "        zi = item_enc(feats)\n",
        "\n",
        "        loss = contrastive_loss(zt, zi, cfg.temperature)\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        sims = (zt @ zi.T)\n",
        "        B = sims.size(0)\n",
        "        targets = torch.arange(B, device=sims.device)\n",
        "\n",
        "        pred = sims.argmax(dim=1)\n",
        "        acc1_list.append((pred == targets).float().mean().item())\n",
        "\n",
        "        pos = sims[targets, targets]\n",
        "        sims[targets, targets] = -1e9\n",
        "        negmax = sims.max(dim=1).values\n",
        "        margin_list.append((pos - negmax).mean().item())\n",
        "\n",
        "    denom = max(1, min(max_batches, len(loader)))\n",
        "    return {\n",
        "        \"loss\": total_loss / denom,\n",
        "        \"acc1\": float(np.mean(acc1_list)) if acc1_list else 0.0,\n",
        "        \"margin\": float(np.mean(margin_list)) if margin_list else 0.0,\n",
        "    }"
      ],
      "metadata": {
        "id": "V6gsieomjzqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = PairDataset(pairs, item_table, text_vocab, cfg, maps, FEATURE_COLS)\n",
        "\n",
        "sampler = StyleFirstSubstyleSecondUniqueSampler(\n",
        "    pairs=pairs,\n",
        "    item_table=item_table,\n",
        "    batch_size=cfg.batch_size,\n",
        "    style_key=\"스타일\",\n",
        "    substyle_key=\"서브스타일\",\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    max_per_style_in_batch=16,      # 256 기준\n",
        "    max_per_none_style_in_batch=8\n",
        ")\n",
        "loader = DataLoader(ds, batch_sampler=sampler, collate_fn=collate_fn, num_workers=0)\n",
        "\n",
        "val_sampler = StyleFirstSubstyleSecondUniqueSampler(\n",
        "    pairs=val_pairs,\n",
        "    item_table=val_item_table,\n",
        "    batch_size=cfg.batch_size,\n",
        "    style_key=\"스타일\",\n",
        "    substyle_key=\"서브스타일\",\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    max_per_style_in_batch=16,\n",
        "    max_per_none_style_in_batch=8\n",
        ")\n",
        "val_loader = DataLoader(val_ds, batch_sampler=val_sampler, collate_fn=collate_fn, num_workers=0)\n",
        "\n",
        "text_enc = TextEncoder(\n",
        "    vocab_size=len(text_vocab.vocab),\n",
        "    emb_dim=cfg.text_emb_dim,\n",
        "    hidden_dim=cfg.text_hidden_dim,\n",
        "    out_dim=cfg.embed_dim,\n",
        "    pad_idx=text_vocab.pad_idx,\n",
        "    use_attn=cfg.text_use_attn,\n",
        "    nhead=cfg.text_attn_nhead,\n",
        "    ff_dim=cfg.text_attn_ff,\n",
        ").to(cfg.device)\n",
        "\n",
        "item_enc = ItemEncoder(\n",
        "    maps=maps,\n",
        "    feature_cols=FEATURE_COLS,\n",
        "    emb_dim=cfg.cat_emb_dim,\n",
        "    hidden_dim=cfg.item_hidden_dim,\n",
        "    out_dim=cfg.embed_dim\n",
        ").to(cfg.device)\n",
        "\n",
        "opt = torch.optim.AdamW(\n",
        "    list(text_enc.parameters()) + list(item_enc.parameters()),\n",
        "    lr=cfg.lr,\n",
        "    weight_decay=cfg.weight_decay\n",
        ")\n",
        "\n",
        "best_val = float(\"inf\")\n",
        "patience = 4\n",
        "min_delta = 1e-3\n",
        "bad_epochs = 0\n",
        "\n",
        "best_state = None\n",
        "\n",
        "for epoch in range(1, 50):  # 최대 50까지 열어두고 early stop으로 자르기\n",
        "    train_loss = train_one_epoch(text_enc, item_enc, loader, opt, cfg)\n",
        "\n",
        "    # train 지표(참고용)\n",
        "    train_metrics = eval_one_epoch(text_enc, item_enc, loader, cfg, max_batches=30)\n",
        "\n",
        "    # val 지표(early stop 기준)\n",
        "    val_metrics = eval_one_epoch(text_enc, item_enc, val_loader, cfg, max_batches=30)\n",
        "\n",
        "    print(\n",
        "        f\"epoch {epoch} | \"\n",
        "        f\"train loss={train_loss:.4f} acc1={train_metrics['acc1']:.3f} margin={train_metrics['margin']:.3f} | \"\n",
        "        f\"val loss={val_metrics['loss']:.4f} acc1={val_metrics['acc1']:.3f} margin={val_metrics['margin']:.3f}\"\n",
        "    )\n",
        "\n",
        "    # early stopping (val loss)\n",
        "    if val_metrics[\"loss\"] < best_val - min_delta:\n",
        "        best_val = val_metrics[\"loss\"]\n",
        "        bad_epochs = 0\n",
        "        # best checkpoint 저장\n",
        "        best_state = {\n",
        "            \"text_enc\": {k: v.cpu() for k, v in text_enc.state_dict().items()},\n",
        "            \"item_enc\": {k: v.cpu() for k, v in item_enc.state_dict().items()},\n",
        "            \"epoch\": epoch,\n",
        "            \"best_val\": best_val,\n",
        "        }\n",
        "    else:\n",
        "        bad_epochs += 1\n",
        "        if bad_epochs >= patience:\n",
        "            print(f\"[EarlyStop] stop at epoch {epoch}. best epoch={best_state['epoch']} best_val={best_state['best_val']:.4f}\")\n",
        "            break\n",
        "\n",
        "# best state 복원\n",
        "if best_state is not None:\n",
        "    text_enc.load_state_dict(best_state[\"text_enc\"])\n",
        "    item_enc.load_state_dict(best_state[\"item_enc\"])\n",
        "    text_enc.to(cfg.device)\n",
        "    item_enc.to(cfg.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVqNncRlhjiZ",
        "outputId": "e207393b-b931-46a4-cd3c-d9ebf43137a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] step 100/333 loss=3.9900\n",
            "[train] step 200/333 loss=3.5708\n",
            "[train] step 300/333 loss=3.4222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 | train loss=3.3872 acc1=0.274 margin=-0.072 | val loss=3.2216 acc1=0.233 margin=-0.084\n",
            "[train] step 100/333 loss=2.7725\n",
            "[train] step 200/333 loss=2.7618\n",
            "[train] step 300/333 loss=2.8121\n",
            "epoch 2 | train loss=2.8205 acc1=0.310 margin=-0.052 | val loss=2.9982 acc1=0.276 margin=-0.065\n",
            "[train] step 100/333 loss=2.5929\n",
            "[train] step 200/333 loss=2.6286\n",
            "[train] step 300/333 loss=2.6890\n",
            "epoch 3 | train loss=2.7083 acc1=0.332 margin=-0.045 | val loss=2.8903 acc1=0.304 margin=-0.060\n",
            "[train] step 100/333 loss=2.5278\n",
            "[train] step 200/333 loss=2.5642\n",
            "[train] step 300/333 loss=2.6392\n",
            "epoch 4 | train loss=2.6572 acc1=0.346 margin=-0.040 | val loss=2.8121 acc1=0.310 margin=-0.054\n",
            "[train] step 100/333 loss=2.4802\n",
            "[train] step 200/333 loss=2.5332\n",
            "[train] step 300/333 loss=2.6049\n",
            "epoch 5 | train loss=2.6259 acc1=0.351 margin=-0.036 | val loss=2.7363 acc1=0.326 margin=-0.046\n",
            "[train] step 100/333 loss=2.4358\n",
            "[train] step 200/333 loss=2.4984\n",
            "[train] step 300/333 loss=2.5787\n",
            "epoch 6 | train loss=2.6011 acc1=0.353 margin=-0.033 | val loss=2.7057 acc1=0.332 margin=-0.044\n",
            "[train] step 100/333 loss=2.4191\n",
            "[train] step 200/333 loss=2.4817\n",
            "[train] step 300/333 loss=2.5643\n",
            "epoch 7 | train loss=2.5888 acc1=0.370 margin=-0.032 | val loss=2.6799 acc1=0.333 margin=-0.043\n",
            "[train] step 100/333 loss=2.3891\n",
            "[train] step 200/333 loss=2.4630\n",
            "[train] step 300/333 loss=2.5481\n",
            "epoch 8 | train loss=2.5700 acc1=0.359 margin=-0.033 | val loss=2.6618 acc1=0.339 margin=-0.042\n",
            "[train] step 100/333 loss=2.3707\n",
            "[train] step 200/333 loss=2.4386\n",
            "[train] step 300/333 loss=2.5261\n",
            "epoch 9 | train loss=2.5485 acc1=0.367 margin=-0.030 | val loss=2.6376 acc1=0.345 margin=-0.041\n",
            "[train] step 100/333 loss=2.3545\n",
            "[train] step 200/333 loss=2.4264\n",
            "[train] step 300/333 loss=2.5091\n",
            "epoch 10 | train loss=2.5328 acc1=0.374 margin=-0.029 | val loss=2.6269 acc1=0.343 margin=-0.040\n",
            "[train] step 100/333 loss=2.3605\n",
            "[train] step 200/333 loss=2.4341\n",
            "[train] step 300/333 loss=2.5173\n",
            "epoch 11 | train loss=2.5375 acc1=0.378 margin=-0.028 | val loss=2.6116 acc1=0.343 margin=-0.040\n",
            "[train] step 100/333 loss=2.3429\n",
            "[train] step 200/333 loss=2.4227\n",
            "[train] step 300/333 loss=2.5085\n",
            "epoch 12 | train loss=2.5302 acc1=0.370 margin=-0.028 | val loss=2.6201 acc1=0.338 margin=-0.042\n",
            "[train] step 100/333 loss=2.3359\n",
            "[train] step 200/333 loss=2.4089\n",
            "[train] step 300/333 loss=2.4940\n",
            "epoch 13 | train loss=2.5165 acc1=0.387 margin=-0.025 | val loss=2.5984 acc1=0.340 margin=-0.041\n",
            "[train] step 100/333 loss=2.3329\n",
            "[train] step 200/333 loss=2.4094\n",
            "[train] step 300/333 loss=2.4908\n",
            "epoch 14 | train loss=2.5137 acc1=0.383 margin=-0.026 | val loss=2.6124 acc1=0.340 margin=-0.042\n",
            "[train] step 100/333 loss=2.3184\n",
            "[train] step 200/333 loss=2.3953\n",
            "[train] step 300/333 loss=2.4751\n",
            "epoch 15 | train loss=2.4994 acc1=0.382 margin=-0.024 | val loss=2.5672 acc1=0.346 margin=-0.037\n",
            "[train] step 100/333 loss=2.3156\n",
            "[train] step 200/333 loss=2.3961\n",
            "[train] step 300/333 loss=2.4776\n",
            "epoch 16 | train loss=2.5020 acc1=0.375 margin=-0.027 | val loss=2.5988 acc1=0.332 margin=-0.040\n",
            "[train] step 100/333 loss=2.3131\n",
            "[train] step 200/333 loss=2.3833\n",
            "[train] step 300/333 loss=2.4687\n",
            "epoch 17 | train loss=2.4904 acc1=0.373 margin=-0.024 | val loss=2.5630 acc1=0.348 margin=-0.038\n",
            "[train] step 100/333 loss=2.2935\n",
            "[train] step 200/333 loss=2.3775\n",
            "[train] step 300/333 loss=2.4641\n",
            "epoch 18 | train loss=2.4877 acc1=0.382 margin=-0.023 | val loss=2.5604 acc1=0.349 margin=-0.037\n",
            "[train] step 100/333 loss=2.3019\n",
            "[train] step 200/333 loss=2.3895\n",
            "[train] step 300/333 loss=2.4711\n",
            "epoch 19 | train loss=2.4933 acc1=0.385 margin=-0.022 | val loss=2.5679 acc1=0.345 margin=-0.036\n",
            "[train] step 100/333 loss=2.2970\n",
            "[train] step 200/333 loss=2.3766\n",
            "[train] step 300/333 loss=2.4606\n",
            "epoch 20 | train loss=2.4826 acc1=0.380 margin=-0.023 | val loss=2.5197 acc1=0.351 margin=-0.034\n",
            "[train] step 100/333 loss=2.2779\n",
            "[train] step 200/333 loss=2.3647\n",
            "[train] step 300/333 loss=2.4482\n",
            "epoch 21 | train loss=2.4727 acc1=0.388 margin=-0.021 | val loss=2.5304 acc1=0.352 margin=-0.034\n",
            "[train] step 100/333 loss=2.2911\n",
            "[train] step 200/333 loss=2.3744\n",
            "[train] step 300/333 loss=2.4548\n",
            "epoch 22 | train loss=2.4769 acc1=0.390 margin=-0.020 | val loss=2.5480 acc1=0.347 margin=-0.036\n",
            "[train] step 100/333 loss=2.2839\n",
            "[train] step 200/333 loss=2.3636\n",
            "[train] step 300/333 loss=2.4496\n",
            "epoch 23 | train loss=2.4739 acc1=0.388 margin=-0.019 | val loss=2.5360 acc1=0.358 margin=-0.035\n",
            "[train] step 100/333 loss=2.2869\n",
            "[train] step 200/333 loss=2.3661\n",
            "[train] step 300/333 loss=2.4519\n",
            "epoch 24 | train loss=2.4725 acc1=0.394 margin=-0.017 | val loss=2.5035 acc1=0.353 margin=-0.032\n",
            "[train] step 100/333 loss=2.2783\n",
            "[train] step 200/333 loss=2.3551\n",
            "[train] step 300/333 loss=2.4383\n",
            "epoch 25 | train loss=2.4627 acc1=0.388 margin=-0.023 | val loss=2.4874 acc1=0.359 margin=-0.031\n",
            "[train] step 100/333 loss=2.2831\n",
            "[train] step 200/333 loss=2.3612\n",
            "[train] step 300/333 loss=2.4470\n",
            "epoch 26 | train loss=2.4696 acc1=0.386 margin=-0.021 | val loss=2.5005 acc1=0.349 margin=-0.033\n",
            "[train] step 100/333 loss=2.2790\n",
            "[train] step 200/333 loss=2.3559\n",
            "[train] step 300/333 loss=2.4370\n",
            "epoch 27 | train loss=2.4603 acc1=0.393 margin=-0.020 | val loss=2.4937 acc1=0.357 margin=-0.033\n",
            "[train] step 100/333 loss=2.2776\n",
            "[train] step 200/333 loss=2.3558\n",
            "[train] step 300/333 loss=2.4406\n",
            "epoch 28 | train loss=2.4615 acc1=0.390 margin=-0.019 | val loss=2.5205 acc1=0.348 margin=-0.036\n",
            "[train] step 100/333 loss=2.2762\n",
            "[train] step 200/333 loss=2.3521\n",
            "[train] step 300/333 loss=2.4313\n",
            "epoch 29 | train loss=2.4537 acc1=0.385 margin=-0.020 | val loss=2.4947 acc1=0.352 margin=-0.034\n",
            "[EarlyStop] stop at epoch 29. best epoch=25 best_val=2.4874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def build_item_index(item_enc: nn.Module, item_table: Dict[str, dict], maps, feature_cols, cfg: Config):\n",
        "    \"\"\"\n",
        "    전체 아이템을 임베딩하여 CPU 텐서로 저장.\n",
        "    반환:\n",
        "      item_embs: (N,d) CPU\n",
        "      item_metas: [{\"item_id\",\"part\"}] (필터/출력용)\n",
        "      item_ids: embedding 순서\n",
        "    \"\"\"\n",
        "    item_enc.eval()\n",
        "    item_ids = list(item_table.keys())\n",
        "    metas = []\n",
        "    embs = []\n",
        "\n",
        "    # 배치 처리\n",
        "    bs = 2048\n",
        "    for i in range(0, len(item_ids), bs):\n",
        "        chunk = item_ids[i:i+bs]\n",
        "\n",
        "        feats_batch = {}\n",
        "        for col in feature_cols:\n",
        "            feats_batch[col] = []\n",
        "\n",
        "        for iid in chunk:\n",
        "            it = item_table[iid]\n",
        "            metas.append({\"item_id\": iid, \"part\": it.get(\"part\", None)})\n",
        "\n",
        "            for col in feature_cols:\n",
        "                m = maps[col]\n",
        "                v = it.get(col, None)\n",
        "                v = \"<unk>\" if (v is None) else str(v)\n",
        "                feats_batch[col].append(m.get(v, 0))\n",
        "\n",
        "        feats_batch = {col: torch.tensor(vals, dtype=torch.long, device=cfg.device) for col, vals in feats_batch.items()}\n",
        "        z = item_enc(feats_batch).detach().cpu()\n",
        "        embs.append(z)\n",
        "\n",
        "    item_embs = torch.cat(embs, dim=0)\n",
        "    return item_embs, metas, item_ids\n",
        "\n",
        "item_embs, item_metas, item_ids = build_item_index(item_enc, item_table, maps, FEATURE_COLS, cfg)\n",
        "print(\"item_embs:\", item_embs.shape, \"CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xal_onPwhm7p",
        "outputId": "0e757107-e651-4103-d148-27d17d7f0ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item_embs: torch.Size([85268, 256]) CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell: SAVE artifacts.pt (drop-in replacement)\n",
        "# =========================\n",
        "import re\n",
        "import math\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# torchtext 버전 저장 (토크나이저 동일성 확보용)\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "SAVE_PATH = \"artifacts.pt\"\n",
        "\n",
        "# -------------------------\n",
        "# 0) 유틸: 후보 변수 자동 탐색\n",
        "# -------------------------\n",
        "def _pick_first_existing(names):\n",
        "    g = globals()\n",
        "    for n in names:\n",
        "        if n in g and g[n] is not None:\n",
        "            return n, g[n]\n",
        "    return None, None\n",
        "\n",
        "def _ensure(cond, msg):\n",
        "    if not cond:\n",
        "        raise RuntimeError(msg)\n",
        "\n",
        "# -------------------------\n",
        "# 1) 반드시 있어야 하는 것들: text_enc, item_enc, cfg, maps, FEATURE_COLS, text_vocab(or stoi/itos)\n",
        "# -------------------------\n",
        "# (A) 모델\n",
        "_, text_enc_ = _pick_first_existing([\"text_enc\", \"text_encoder\", \"te\", \"te2\"])\n",
        "_, item_enc_ = _pick_first_existing([\"item_enc\", \"item_encoder\", \"ie\", \"ie2\"])\n",
        "_ensure(text_enc_ is not None, \"text_enc 모델 변수를 찾지 못했습니다. (예: text_enc)\")\n",
        "_ensure(item_enc_ is not None, \"item_enc 모델 변수를 찾지 못했습니다. (예: item_enc)\")\n",
        "\n",
        "# (B) cfg\n",
        "_, cfg_ = _pick_first_existing([\"cfg\", \"CFG\"])\n",
        "_ensure(cfg_ is not None, \"cfg 변수를 찾지 못했습니다. (예: cfg.max_len 등)\")\n",
        "\n",
        "# (C) maps / FEATURE_COLS\n",
        "_, maps_ = _pick_first_existing([\"maps\", \"MAPS\"])\n",
        "_, feature_cols_ = _pick_first_existing([\"FEATURE_COLS\", \"feature_cols\"])\n",
        "_ensure(maps_ is not None, \"maps 변수를 찾지 못했습니다.\")\n",
        "_ensure(feature_cols_ is not None, \"FEATURE_COLS 변수를 찾지 못했습니다.\")\n",
        "_ensure(isinstance(feature_cols_, (list, tuple)) and len(feature_cols_) > 0, \"FEATURE_COLS가 비어있거나 타입이 이상합니다.\")\n",
        "\n",
        "# (D) text_vocab (itos/stoi)\n",
        "# - 당신 코드에서 text_vocab.vocab.get_itos/get_stoi 구조일 가능성이 큼\n",
        "name_tv, text_vocab_ = _pick_first_existing([\"text_vocab\", \"tv\", \"tv2\"])\n",
        "if text_vocab_ is not None and hasattr(text_vocab_, \"vocab\"):\n",
        "    itos_ = text_vocab_.vocab.get_itos()\n",
        "    stoi_ = text_vocab_.vocab.get_stoi()\n",
        "    pad_idx_ = int(getattr(text_vocab_, \"pad_idx\"))\n",
        "    unk_idx_ = int(getattr(text_vocab_, \"unk_idx\"))\n",
        "else:\n",
        "    # 혹시 itos/stoi만 따로 존재하는 형태였으면 fallback\n",
        "    _, itos_ = _pick_first_existing([\"itos\"])\n",
        "    _, stoi_ = _pick_first_existing([\"stoi\"])\n",
        "    _, pad_idx_ = _pick_first_existing([\"pad_idx\"])\n",
        "    _, unk_idx_ = _pick_first_existing([\"unk_idx\"])\n",
        "    _ensure(itos_ is not None and stoi_ is not None, \"text_vocab도 없고 itos/stoi도 없습니다. vocab 저장이 불가능합니다.\")\n",
        "    _ensure(pad_idx_ is not None and unk_idx_ is not None, \"pad_idx/unk_idx가 없습니다.\")\n",
        "    pad_idx_ = int(pad_idx_); unk_idx_ = int(unk_idx_)\n",
        "\n",
        "# -------------------------\n",
        "# 2) item_embs / item_metas: 가장 중요\n",
        "# -------------------------\n",
        "# 보통은 embs/metas 또는 item_embs/item_metas로 이미 만들어져 있을 수 있음\n",
        "name_embs, embs_ = _pick_first_existing([\"item_embs\", \"embs\", \"embs2\", \"all_item_embs\"])\n",
        "name_metas, metas_ = _pick_first_existing([\"item_metas\", \"metas\", \"metas2\", \"all_item_metas\"])\n",
        "\n",
        "_ensure(embs_ is not None, \"아이템 임베딩 텐서(embs/item_embs)를 찾지 못했습니다. 임베딩 생성 셀을 먼저 실행하세요.\")\n",
        "_ensure(metas_ is not None, \"아이템 메타 리스트(metas/item_metas)를 찾지 못했습니다. 메타 생성 셀을 먼저 실행하세요.\")\n",
        "_ensure(isinstance(metas_, list) and len(metas_) > 0, \"metas가 list가 아니거나 비어있습니다.\")\n",
        "\n",
        "# 텐서 형태 체크\n",
        "_ensure(isinstance(embs_, torch.Tensor) and embs_.dim() == 2, f\"embs 텐서 shape가 이상합니다: {type(embs_)}, {getattr(embs_, 'shape', None)}\")\n",
        "_ensure(len(metas_) == embs_.shape[0], f\"embs(N={embs_.shape[0]})와 metas(len={len(metas_)}) 길이가 다릅니다.\")\n",
        "\n",
        "item_embs = embs_.detach().cpu().contiguous()\n",
        "item_metas = metas_\n",
        "\n",
        "# -------------------------\n",
        "# 3) item_table_min: 없으면 item_metas에서라도 만들기 (CPU 추천에 필요)\n",
        "# -------------------------\n",
        "def _build_item_table_min_from_metas(metas_list):\n",
        "    out = {}\n",
        "    for m in metas_list:\n",
        "        # item_id 키 후보 대응\n",
        "        iid = m.get(\"item_id\", None) or m.get(\"image_id\", None) or m.get(\"id\", None)\n",
        "        if iid is None:\n",
        "            continue\n",
        "        iid = str(iid)\n",
        "        part = m.get(\"part\", None) or m.get(\"category\", None)\n",
        "        tr = m.get(\"temp_range\", None)\n",
        "        if tr is None:\n",
        "            tr = (-50, 50)\n",
        "        # temp_range 정규화\n",
        "        try:\n",
        "            tmin, tmax = tr\n",
        "            tmin = int(tmin); tmax = int(tmax)\n",
        "            tr = (tmin, tmax)\n",
        "        except:\n",
        "            tr = (-50, 50)\n",
        "        out[iid] = {\"part\": part, \"temp_range\": tr}\n",
        "    return out\n",
        "\n",
        "name_item_table, item_table_ = _pick_first_existing([\"item_table\", \"item_table_min\"])\n",
        "if item_table_ is None:\n",
        "    item_table_min = _build_item_table_min_from_metas(item_metas)\n",
        "else:\n",
        "    # item_table이 원본(full)일 수도 있고, 이미 min일 수도 있음\n",
        "    # CPU 추천에 필요한 키만 뽑아 최소 테이블로 축소\n",
        "    item_table_min = {}\n",
        "    if isinstance(item_table_, dict):\n",
        "        # dict keyed by item_id assumed\n",
        "        for iid, row in item_table_.items():\n",
        "            if not isinstance(row, dict):\n",
        "                continue\n",
        "            part = row.get(\"part\", None) or row.get(\"category\", None)\n",
        "            tr = row.get(\"temp_range\", None) or row.get(\"temp\", None)\n",
        "            if tr is None:\n",
        "                tr = (-50, 50)\n",
        "            try:\n",
        "                tmin, tmax = tr\n",
        "                tr = (int(tmin), int(tmax))\n",
        "            except:\n",
        "                tr = (-50, 50)\n",
        "            item_table_min[str(iid)] = {\"part\": part, \"temp_range\": tr}\n",
        "    else:\n",
        "        # 이상한 타입이면 metas 기반 생성\n",
        "        item_table_min = _build_item_table_min_from_metas(item_metas)\n",
        "\n",
        "_ensure(len(item_table_min) > 0, \"item_table_min 생성에 실패했습니다. metas에 item_id가 있는지 확인 필요.\")\n",
        "\n",
        "# -------------------------\n",
        "# 4) WEATHER_LABEL_TO_TEMP_RANGE: 있으면 저장(권장). 없으면 빈 dict로 저장\n",
        "# -------------------------\n",
        "name_wmap, wmap_ = _pick_first_existing([\"WEATHER_LABEL_TO_TEMP_RANGE\", \"weather_label_to_temp_range\", \"weather_map\"])\n",
        "if wmap_ is None:\n",
        "    WEATHER_LABEL_TO_TEMP_RANGE = {}\n",
        "else:\n",
        "    WEATHER_LABEL_TO_TEMP_RANGE = wmap_\n",
        "\n",
        "# -------------------------\n",
        "# 5) cfg를 dict로 (CPU에서 모델 재구성에 필요)\n",
        "# -------------------------\n",
        "def _getattr(cfgobj, key, default=None):\n",
        "    return getattr(cfgobj, key, default)\n",
        "\n",
        "cfg_dict = dict(\n",
        "    max_len=int(_getattr(cfg_, \"max_len\")),\n",
        "    text_emb_dim=int(_getattr(cfg_, \"text_emb_dim\")),\n",
        "    text_hidden_dim=int(_getattr(cfg_, \"text_hidden_dim\")),\n",
        "    cat_emb_dim=int(_getattr(cfg_, \"cat_emb_dim\")),\n",
        "    item_hidden_dim=int(_getattr(cfg_, \"item_hidden_dim\")),\n",
        "    embed_dim=int(_getattr(cfg_, \"embed_dim\")),\n",
        "    temperature=float(_getattr(cfg_, \"temperature\", 0.07)),\n",
        "\n",
        "    # Self-attention 옵션 (학습에서 사용했다면 반드시 저장해야 CPU에서 동일 구조로 로드 가능)\n",
        "    text_use_attn=bool(_getattr(cfg_, \"text_use_attn\", False)),\n",
        "    text_attn_nhead=int(_getattr(cfg_, \"text_attn_nhead\", 4)),\n",
        "    text_attn_ff=int(_getattr(cfg_, \"text_attn_ff\", 256)),\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 6) 모델 state_dict CPU로 저장\n",
        "# -------------------------\n",
        "text_state = {k: v.detach().cpu() for k, v in text_enc_.state_dict().items()}\n",
        "item_state = {k: v.detach().cpu() for k, v in item_enc_.state_dict().items()}\n",
        "\n",
        "# -------------------------\n",
        "# 7) payload 구성\n",
        "# -------------------------\n",
        "payload = {\n",
        "    \"versions\": {\n",
        "        \"torch\": torch.__version__,\n",
        "        \"torchtext\": torchtext.__version__,\n",
        "        \"tokenizer\": \"torchtext.get_tokenizer('basic_english')\",\n",
        "    },\n",
        "    \"cfg\": cfg_dict,\n",
        "    \"FEATURE_COLS\": list(feature_cols_),\n",
        "    \"maps\": maps_,\n",
        "    \"text_vocab\": {\n",
        "        \"itos\": list(itos_),\n",
        "        \"stoi\": dict(stoi_),\n",
        "        \"pad_idx\": int(pad_idx_),\n",
        "        \"unk_idx\": int(unk_idx_),\n",
        "    },\n",
        "    \"text_enc_state\": text_state,\n",
        "    \"item_enc_state\": item_state,\n",
        "    \"item_embs\": item_embs,\n",
        "    \"item_metas\": item_metas,\n",
        "    \"item_table_min\": item_table_min,\n",
        "    \"WEATHER_LABEL_TO_TEMP_RANGE\": WEATHER_LABEL_TO_TEMP_RANGE,\n",
        "}\n",
        "\n",
        "torch.save(payload, SAVE_PATH)\n",
        "\n",
        "print(\"✅ Saved:\", SAVE_PATH)\n",
        "print(\"  - used embs var:\", name_embs, \"shape:\", tuple(item_embs.shape))\n",
        "print(\"  - used metas var:\", name_metas, \"len:\", len(item_metas))\n",
        "print(\"  - item_table_min:\", len(item_table_min))\n",
        "print(\"  - versions:\", payload[\"versions\"])\n",
        "print(\"  - cfg(text_use_attn):\", cfg_dict[\"text_use_attn\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZUuyJGxsD1R",
        "outputId": "a2789553-b989-4d0c-964d-ab606f6b4cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: artifacts.pt\n",
            "  - used embs var: item_embs shape: (85268, 256)\n",
            "  - used metas var: item_metas len: 85268\n",
            "  - item_table_min: 85268\n",
            "  - versions: {'torch': '2.5.1+cu121', 'torchtext': '0.6.0', 'tokenizer': \"torchtext.get_tokenizer('basic_english')\"}\n",
            "  - cfg(text_use_attn): True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def recommend_from_closet_cpu(\n",
        "    text_enc_cpu,\n",
        "    text_vocab,\n",
        "    item_embs_all: torch.Tensor,      # (N,d) CPU\n",
        "    item_metas_all: List[dict],       # aligned with item_embs_all, includes item_id, part\n",
        "    item_table_all: Dict[str, dict],  # includes temp_range, part etc.\n",
        "    user_closet_ids: List[str],\n",
        "    query: str,\n",
        "    current_temp_text: str,           # 날씨 API에서 온 문자열\n",
        "    k: int = 5,\n",
        "    parts: Tuple[str, ...] = (\"상의\", \"하의\", \"아우터\", \"원피스\"),\n",
        "    temp_margin: int = 2,             # 필터 여유(정수 °C)\n",
        "    print_topm: int = 5,\n",
        "):\n",
        "    # 0) temp parse\n",
        "    current_temp = parse_temperature_to_int(current_temp_text)\n",
        "\n",
        "    closet_set = set(map(str, user_closet_ids))\n",
        "\n",
        "    # 1) 옷장 제한\n",
        "    keep_idx = [i for i, m in enumerate(item_metas_all) if m[\"item_id\"] in closet_set]\n",
        "    if len(keep_idx) == 0:\n",
        "        raise ValueError(\"옷장 item_id가 인덱스에 하나도 없습니다.\")\n",
        "\n",
        "    idx_t = torch.tensor(keep_idx, dtype=torch.long)\n",
        "    embs_closet = item_embs_all.index_select(0, idx_t)           # (M,d)\n",
        "    metas_closet = [item_metas_all[i] for i in keep_idx]         # length M\n",
        "\n",
        "    # 2) 기온 필터\n",
        "    temp_ok = []\n",
        "    for m in metas_closet:\n",
        "        iid = m[\"item_id\"]\n",
        "        tmin, tmax = item_table_all[iid][\"temp_range\"]\n",
        "        temp_ok.append((tmin - temp_margin) <= current_temp <= (tmax + temp_margin))\n",
        "    temp_ok = torch.tensor(temp_ok, dtype=torch.bool)            # (M,)\n",
        "\n",
        "    # 3) 텍스트 임베딩 (CPU)\n",
        "    text_enc_cpu.eval()\n",
        "    ids, attn = text_vocab.encode(query, cfg.max_len)\n",
        "    zt = text_enc_cpu(ids.unsqueeze(0), attn.unsqueeze(0)).cpu() # (1,d)\n",
        "\n",
        "    # 4) 유사도\n",
        "    sims = (zt @ embs_closet.T).squeeze(0)                       # (M,)\n",
        "\n",
        "    # 출력 요약\n",
        "    total_closet = len(metas_closet)\n",
        "    passed = int(temp_ok.sum().item())\n",
        "    print(\"=\" * 72)\n",
        "    print(\"INPUT\")\n",
        "    print(f\"- query: {query}\")\n",
        "    print(f\"- current_temp_text: {current_temp_text}  -> parsed: {current_temp}°C (margin={temp_margin})\")\n",
        "    print(f\"- closet items: {total_closet}\")\n",
        "    print(f\"- after temp filter: {passed}\")\n",
        "    print(\"=\" * 72)\n",
        "\n",
        "    results = {}\n",
        "    for part in parts:\n",
        "        part_mask = torch.tensor([m.get(\"part\", None) == part for m in metas_closet], dtype=torch.bool)\n",
        "        mask = temp_ok & part_mask\n",
        "\n",
        "        if mask.sum() == 0:\n",
        "            results[part] = []\n",
        "            print(f\"[{part}] no candidates after temp filter.\")\n",
        "            continue\n",
        "\n",
        "        sims_f = sims.clone()\n",
        "        sims_f[~mask] = -1e9\n",
        "\n",
        "        topv, topi = torch.topk(sims_f, k=min(k, int(mask.sum().item())))\n",
        "        rows = []\n",
        "        for score, local_idx in zip(topv.tolist(), topi.tolist()):\n",
        "            iid = metas_closet[local_idx][\"item_id\"]\n",
        "            tmin, tmax = item_table_all[iid][\"temp_range\"]\n",
        "            rows.append({\"item_id\": iid, \"score\": float(score), \"temp_range\": (tmin, tmax), \"part\": part})\n",
        "\n",
        "        results[part] = rows\n",
        "\n",
        "        print(f\"\\n[{part}] top-{len(rows)}\")\n",
        "        print(\"-\" * 72)\n",
        "        print(f\"{'rank':>4} | {'item_id':<12} | {'score(cos)':>10} | {'temp_range':>15}\")\n",
        "        print(\"-\" * 72)\n",
        "        for r, row in enumerate(rows[:print_topm], 1):\n",
        "            tr = f\"{row['temp_range'][0]}~{row['temp_range'][1]}\"\n",
        "            print(f\"{r:>4} | {row['item_id']:<12} | {row['score']:>10.4f} | {tr:>15}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 72)\n",
        "    return results"
      ],
      "metadata": {
        "id": "mIzVspSYh5_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU로 옮겨서 \"로컬 추론\" 시뮬레이션\n",
        "text_enc_cpu = text_enc.to(\"cpu\").eval()\n",
        "\n",
        "# 예시 옷장: train 아이템 중 일부를 샘플로\n",
        "user_closet_ids = random.sample(list(item_table.keys()), 200)  # 예: 옷장 200개\n",
        "\n",
        "query = \"캐주얼한 주말 카페룩\"\n",
        "current_temp_text = \"23도\"  # 날씨 API에서 왔다고 가정\n",
        "\n",
        "res = recommend_from_closet_cpu(\n",
        "    text_enc_cpu=text_enc_cpu,\n",
        "    text_vocab=text_vocab,\n",
        "    item_embs_all=item_embs,\n",
        "    item_metas_all=item_metas,\n",
        "    item_table_all=item_table,\n",
        "    user_closet_ids=user_closet_ids,\n",
        "    query=query,\n",
        "    current_temp_text=current_temp_text,\n",
        "    k=5,\n",
        "    parts=(\"상의\", \"하의\", \"아우터\", \"원피스\"),\n",
        "    temp_margin=2\n",
        ")\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1o409Oxh9Na",
        "outputId": "316c9cb2-f367-4443-cfed-c2fd91d41cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================\n",
            "INPUT\n",
            "- query: 캐주얼한 주말 카페룩\n",
            "- current_temp_text: 23도  -> parsed: 23°C (margin=2)\n",
            "- closet items: 200\n",
            "- after temp filter: 37\n",
            "========================================================================\n",
            "\n",
            "[상의] top-5\n",
            "------------------------------------------------------------------------\n",
            "rank | item_id      | score(cos) |      temp_range\n",
            "------------------------------------------------------------------------\n",
            "   1 | 589587       |     0.1575 |           19~27\n",
            "   2 | 128507       |     0.1304 |           19~27\n",
            "   3 | 889882       |     0.1174 |           19~27\n",
            "   4 | 148257       |     0.0823 |           19~27\n",
            "   5 | 521239       |     0.0798 |           19~27\n",
            "\n",
            "[하의] top-5\n",
            "------------------------------------------------------------------------\n",
            "rank | item_id      | score(cos) |      temp_range\n",
            "------------------------------------------------------------------------\n",
            "   1 | 1128835      |     0.2923 |           19~27\n",
            "   2 | 104060       |     0.2199 |           19~27\n",
            "   3 | 263665       |     0.1667 |           19~27\n",
            "   4 | 528091       |     0.1400 |           19~27\n",
            "   5 | 1252603      |     0.0633 |           19~27\n",
            "\n",
            "[아우터] top-5\n",
            "------------------------------------------------------------------------\n",
            "rank | item_id      | score(cos) |      temp_range\n",
            "------------------------------------------------------------------------\n",
            "   1 | 909929       |     0.3149 |           19~27\n",
            "   2 | 148559       |     0.1276 |           19~27\n",
            "   3 | 1248024      |     0.0313 |           19~27\n",
            "   4 | 607730       |     0.0289 |           19~27\n",
            "   5 | 1053038      |    -0.0254 |           19~27\n",
            "\n",
            "[원피스] top-5\n",
            "------------------------------------------------------------------------\n",
            "rank | item_id      | score(cos) |      temp_range\n",
            "------------------------------------------------------------------------\n",
            "   1 | 145503       |     0.3303 |           19~27\n",
            "   2 | 198215       |     0.1757 |           19~27\n",
            "   3 | 68251        |     0.1260 |           19~27\n",
            "   4 | 987740       |     0.1060 |           19~27\n",
            "   5 | 849535       |    -0.1314 |           19~27\n",
            "\n",
            "========================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'상의': [{'item_id': '589587',\n",
              "   'score': 0.15745878219604492,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '상의'},\n",
              "  {'item_id': '128507',\n",
              "   'score': 0.13044287264347076,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '상의'},\n",
              "  {'item_id': '889882',\n",
              "   'score': 0.11739128082990646,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '상의'},\n",
              "  {'item_id': '148257',\n",
              "   'score': 0.08225806057453156,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '상의'},\n",
              "  {'item_id': '521239',\n",
              "   'score': 0.0798206552863121,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '상의'}],\n",
              " '하의': [{'item_id': '1128835',\n",
              "   'score': 0.29232022166252136,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '하의'},\n",
              "  {'item_id': '104060',\n",
              "   'score': 0.2199350893497467,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '하의'},\n",
              "  {'item_id': '263665',\n",
              "   'score': 0.16668395698070526,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '하의'},\n",
              "  {'item_id': '528091',\n",
              "   'score': 0.14000949263572693,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '하의'},\n",
              "  {'item_id': '1252603',\n",
              "   'score': 0.06330203264951706,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '하의'}],\n",
              " '아우터': [{'item_id': '909929',\n",
              "   'score': 0.3148806393146515,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '아우터'},\n",
              "  {'item_id': '148559',\n",
              "   'score': 0.12763553857803345,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '아우터'},\n",
              "  {'item_id': '1248024',\n",
              "   'score': 0.031308356672525406,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '아우터'},\n",
              "  {'item_id': '607730',\n",
              "   'score': 0.028891105204820633,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '아우터'},\n",
              "  {'item_id': '1053038',\n",
              "   'score': -0.02535366080701351,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '아우터'}],\n",
              " '원피스': [{'item_id': '145503',\n",
              "   'score': 0.3303271234035492,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '원피스'},\n",
              "  {'item_id': '198215',\n",
              "   'score': 0.17574413120746613,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '원피스'},\n",
              "  {'item_id': '68251',\n",
              "   'score': 0.1260077804327011,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '원피스'},\n",
              "  {'item_id': '987740',\n",
              "   'score': 0.10603625327348709,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '원피스'},\n",
              "  {'item_id': '849535',\n",
              "   'score': -0.131361186504364,\n",
              "   'temp_range': (19, 27),\n",
              "   'part': '원피스'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchtext\n",
        "\n",
        "def serialize_text_vocab(text_vocab) -> dict:\n",
        "    vocab = text_vocab.vocab\n",
        "    return {\n",
        "        \"itos\": vocab.get_itos(),\n",
        "        \"stoi\": dict(vocab.get_stoi()),\n",
        "        \"pad_idx\": int(text_vocab.pad_idx),\n",
        "        \"unk_idx\": int(text_vocab.unk_idx),\n",
        "    }\n",
        "\n",
        "def norm_temp_range(tr):\n",
        "    try:\n",
        "        a, b = tr\n",
        "        return (int(a), int(b))\n",
        "    except:\n",
        "        return (-50, 50)\n",
        "\n",
        "cfg_dict = dict(\n",
        "    max_len=int(cfg.max_len),\n",
        "    text_emb_dim=int(cfg.text_emb_dim),\n",
        "    text_hidden_dim=int(cfg.text_hidden_dim),\n",
        "    cat_emb_dim=int(cfg.cat_emb_dim),\n",
        "    item_hidden_dim=int(cfg.item_hidden_dim),\n",
        "    embed_dim=int(cfg.embed_dim),\n",
        "    temperature=float(getattr(cfg, \"temperature\", 0.07)),\n",
        "    text_use_attn=bool(getattr(cfg, \"text_use_attn\", False)),\n",
        "    text_attn_nhead=int(getattr(cfg, \"text_attn_nhead\", 4)),\n",
        "    text_attn_ff=int(getattr(cfg, \"text_attn_ff\", 256)),\n",
        ")\n",
        "\n",
        "SAVE_PATH = \"kfashion_contrastive_artifacts.pt\"\n",
        "\n",
        "payload = {\n",
        "    \"versions\": {\"torch\": torch.__version__, \"torchtext\": torchtext.__version__},\n",
        "\n",
        "    \"cfg\": cfg_dict,\n",
        "    \"FEATURE_COLS\": FEATURE_COLS,\n",
        "    \"WEATHER_LABEL_TO_TEMP_RANGE\": WEATHER_LABEL_TO_TEMP_RANGE,\n",
        "\n",
        "    \"text_vocab\": serialize_text_vocab(text_vocab),\n",
        "    \"maps\": maps,\n",
        "\n",
        "    \"text_enc_state\": {k: v.detach().cpu() for k, v in text_enc.state_dict().items()},\n",
        "    \"item_enc_state\": {k: v.detach().cpu() for k, v in item_enc.state_dict().items()},\n",
        "\n",
        "    \"item_embs\": item_embs.detach().cpu().contiguous(),\n",
        "    \"item_metas\": item_metas,\n",
        "\n",
        "    \"item_table_min\": {\n",
        "        str(iid): {\n",
        "            \"part\": item_table[iid].get(\"part\", None),\n",
        "            \"temp_range\": norm_temp_range(item_table[iid].get(\"temp_range\", (-50, 50))),\n",
        "        } for iid in item_table\n",
        "    },\n",
        "}\n",
        "\n",
        "torch.save(payload, SAVE_PATH)\n",
        "print(\"Saved:\", SAVE_PATH)\n",
        "print(\"item_embs:\", payload[\"item_embs\"].shape, \"metas:\", len(payload[\"item_metas\"]))\n",
        "print(\"versions:\", payload[\"versions\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK2fUntgiK0W",
        "outputId": "56cb1573-728d-435b-8a58-26750e6061c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: kfashion_contrastive_artifacts.pt\n",
            "item_embs: torch.Size([85268, 256]) metas: 85268\n",
            "versions: {'torch': '2.5.1+cu121', 'torchtext': '0.6.0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "v2SId7XAqPNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer"
      ],
      "metadata": {
        "id": "a5OAAAB6vK3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_temperature_to_int(temp_text: str) -> int:\n",
        "    s = str(temp_text).strip()\n",
        "    negative = False\n",
        "    if \"영하\" in s or s.startswith(\"-\"):\n",
        "        negative = True\n",
        "    m = re.search(r\"(-?\\d+(\\.\\d+)?)\", s)\n",
        "    if not m:\n",
        "        raise ValueError(f\"Cannot parse temperature: {temp_text}\")\n",
        "    val = float(m.group(1))\n",
        "    if negative and val > 0:\n",
        "        val = -val\n",
        "    return int(round(val))\n",
        "\n",
        "\n",
        "def safe_temp_range(tr, default=(-50, 50)) -> Tuple[int, int]:\n",
        "    # tr가 (min,max) tuple/list/문자열 등 뭐가 와도 최대한 안전하게 (int,int)로 정규화\n",
        "    if tr is None:\n",
        "        return default\n",
        "    if isinstance(tr, (list, tuple)) and len(tr) == 2:\n",
        "        try:\n",
        "            return (int(tr[0]), int(tr[1]))\n",
        "        except:\n",
        "            return default\n",
        "    if isinstance(tr, str):\n",
        "        # \"[0,10]\" 같은 문자열 대응\n",
        "        nums = re.findall(r\"-?\\d+\", tr)\n",
        "        if len(nums) >= 2:\n",
        "            try:\n",
        "                return (int(nums[0]), int(nums[1]))\n",
        "            except:\n",
        "                return default\n",
        "    return default\n",
        "\n",
        "\n",
        "def normalize_str(x) -> Optional[str]:\n",
        "    if x is None:\n",
        "        return None\n",
        "    if isinstance(x, float) and pd.isna(x):\n",
        "        return None\n",
        "    s = str(x).strip()\n",
        "    if s in (\"\", \"없음\", \"None\", \"nan\", \"NaN\"):\n",
        "        return None\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_item_id(meta: dict) -> str:\n",
        "    # meta dict에서 item_id를 robust하게 꺼냄\n",
        "    for k in (\"item_id\", \"image_id\", \"id\", \"ID\"):\n",
        "        if k in meta and meta[k] is not None:\n",
        "            return str(meta[k])\n",
        "    raise KeyError(f\"meta에 item_id/image_id/id 키가 없습니다. meta keys={list(meta.keys())}\")\n",
        "\n",
        "\n",
        "# part alias: 한글/영문/축약 혼재 대응\n",
        "PART_ALIAS = {\n",
        "    \"top\": \"상의\",\n",
        "    \"upper\": \"상의\",\n",
        "    \"상의\": \"상의\",\n",
        "\n",
        "    \"bottom\": \"하의\",\n",
        "    \"pants\": \"하의\",\n",
        "    \"trousers\": \"하의\",\n",
        "    \"하의\": \"하의\",\n",
        "\n",
        "    \"outer\": \"아우터\",\n",
        "    \"outerwear\": \"아우터\",\n",
        "    \"아우터\": \"아우터\",\n",
        "\n",
        "    \"dress\": \"원피스\",\n",
        "    \"onepiece\": \"원피스\",\n",
        "    \"원피스\": \"원피스\",\n",
        "}\n",
        "\n",
        "def normalize_part(x) -> Optional[str]:\n",
        "    s = normalize_str(x)\n",
        "    if s is None:\n",
        "        return None\n",
        "    key = s.strip().lower()\n",
        "    return PART_ALIAS.get(key, s)  # alias 없으면 원본 유지\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RuntimeConfig:\n",
        "    max_len: int\n",
        "    text_emb_dim: int\n",
        "    text_hidden_dim: int\n",
        "    cat_emb_dim: int\n",
        "    item_hidden_dim: int\n",
        "    embed_dim: int\n",
        "    temperature: float\n",
        "    text_use_attn: bool = False\n",
        "    text_attn_nhead: int = 4\n",
        "    text_attn_ff: int = 256"
      ],
      "metadata": {
        "id": "jjmG08PgvMPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    - 기본: Embedding -> masked mean pooling -> MLP -> normalize\n",
        "    - 옵션: 1-layer self-attention\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size: int, emb_dim: int, hidden_dim: int, out_dim: int, pad_idx: int,\n",
        "                 use_attn: bool = False, nhead: int = 4, ff_dim: int = 256):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
        "        self.use_attn = use_attn\n",
        "        if use_attn:\n",
        "            layer = nn.TransformerEncoderLayer(\n",
        "                d_model=emb_dim, nhead=nhead, dim_feedforward=ff_dim, batch_first=True\n",
        "            )\n",
        "            self.attn = nn.TransformerEncoder(layer, num_layers=1)\n",
        "        else:\n",
        "            self.attn = None\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(emb_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.emb(input_ids)  # (B,L,D)\n",
        "\n",
        "        if self.use_attn:\n",
        "            key_padding_mask = (attention_mask == 0)  # True=mask\n",
        "            x = self.attn(x, src_key_padding_mask=key_padding_mask)\n",
        "\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        x = x * mask\n",
        "        denom = mask.sum(dim=1).clamp_min(1.0)\n",
        "        pooled = x.sum(dim=1) / denom\n",
        "\n",
        "        z = self.mlp(pooled)\n",
        "        return F.normalize(z, dim=-1)\n",
        "\n",
        "\n",
        "class ItemEncoder(nn.Module):\n",
        "    def __init__(self, maps, feature_cols, emb_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.feature_cols = feature_cols\n",
        "        self.embs = nn.ModuleDict({col: nn.Embedding(len(maps[col]), emb_dim) for col in feature_cols})\n",
        "        in_dim = emb_dim * len(feature_cols)\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, feats: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        vecs = []\n",
        "        for col in self.feature_cols:\n",
        "            vecs.append(self.embs[col](feats[col]))\n",
        "        x = torch.cat(vecs, dim=1)\n",
        "        z = self.proj(x)\n",
        "        return F.normalize(z, dim=-1)"
      ],
      "metadata": {
        "id": "NMpR9Wh6vO-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ART_PATH = \"artifacts.pt\"  # 필요 시 경로 수정\n",
        "\n",
        "payload = torch.load(ART_PATH, map_location=\"cpu\")\n",
        "\n",
        "# 버전 체크(토크나이저 동일성에 영향 가능)\n",
        "saved_versions = payload.get(\"versions\", {})\n",
        "print(\"[saved versions]\", saved_versions)\n",
        "print(\"[local versions]\", {\"torch\": torch.__version__, \"torchtext\": torchtext.__version__})\n",
        "if saved_versions.get(\"torchtext\") and saved_versions[\"torchtext\"] != torchtext.__version__:\n",
        "    print(\"WARNING: torchtext version mismatch -> tokenizer behavior may differ (성능 변동 가능)\")\n",
        "\n",
        "cfg = RuntimeConfig(**payload[\"cfg\"])\n",
        "FEATURE_COLS = payload[\"FEATURE_COLS\"]\n",
        "maps = payload[\"maps\"]\n",
        "\n",
        "tv = payload[\"text_vocab\"]\n",
        "itos = tv[\"itos\"]\n",
        "stoi = tv[\"stoi\"]\n",
        "pad_idx = int(tv[\"pad_idx\"])\n",
        "unk_idx = int(tv[\"unk_idx\"])\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")  # ✅ 동일 API\n",
        "\n",
        "# 모델 구성 (주의: cfg.text_use_attn 여부가 저장된 구조와 동일해야 로딩됨)\n",
        "text_enc = TextEncoder(\n",
        "    vocab_size=len(itos),\n",
        "    emb_dim=cfg.text_emb_dim,\n",
        "    hidden_dim=cfg.text_hidden_dim,\n",
        "    out_dim=cfg.embed_dim,\n",
        "    pad_idx=pad_idx,\n",
        "    use_attn=cfg.text_use_attn,\n",
        "    nhead=cfg.text_attn_nhead,\n",
        "    ff_dim=cfg.text_attn_ff,\n",
        ").eval()\n",
        "\n",
        "item_enc = ItemEncoder(\n",
        "    maps=maps,\n",
        "    feature_cols=FEATURE_COLS,\n",
        "    emb_dim=cfg.cat_emb_dim,\n",
        "    hidden_dim=cfg.item_hidden_dim,\n",
        "    out_dim=cfg.embed_dim,\n",
        ").eval()\n",
        "\n",
        "text_enc.load_state_dict(payload[\"text_enc_state\"])\n",
        "item_enc.load_state_dict(payload[\"item_enc_state\"])\n",
        "\n",
        "# 인덱스\n",
        "item_embs = payload[\"item_embs\"].float().contiguous()   # (N,d)\n",
        "item_metas = payload[\"item_metas\"]                      # list aligned\n",
        "\n",
        "# 최소 테이블(없어도 동작하게 방어)\n",
        "item_table_min = payload.get(\"item_table_min\", {})\n",
        "WEATHER_LABEL_TO_TEMP_RANGE = payload.get(\"WEATHER_LABEL_TO_TEMP_RANGE\", {})\n",
        "\n",
        "print(\"Loaded index:\", item_embs.shape, \"metas:\", len(item_metas))"
      ],
      "metadata": {
        "id": "_eTzp0iPvSv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def encode_text(query: str) -> torch.Tensor:\n",
        "    tokens = tokenizer(query)\n",
        "    ids = [stoi.get(t, unk_idx) for t in tokens][: cfg.max_len]\n",
        "    attn = [1] * len(ids)\n",
        "    if len(ids) < cfg.max_len:\n",
        "        pad_len = cfg.max_len - len(ids)\n",
        "        ids += [pad_idx] * pad_len\n",
        "        attn += [0] * pad_len\n",
        "\n",
        "    input_ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n",
        "    attention = torch.tensor(attn, dtype=torch.long).unsqueeze(0)\n",
        "    z = text_enc(input_ids, attention).cpu()  # (1,d)\n",
        "    return z\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def encode_items_from_df(df: pd.DataFrame, id_col: str = \"image_id\") -> Tuple[torch.Tensor, List[dict]]:\n",
        "    if id_col not in df.columns:\n",
        "        raise ValueError(f\"df must include id_col='{id_col}'\")\n",
        "\n",
        "    # feature cols 누락 방어: 없으면 None으로 채워서 <unk>로 들어가게\n",
        "    for col in FEATURE_COLS:\n",
        "        if col not in df.columns:\n",
        "            df[col] = None\n",
        "\n",
        "    feats = {col: [] for col in FEATURE_COLS}\n",
        "    metas = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        iid = str(row[id_col])\n",
        "\n",
        "        # part\n",
        "        part = normalize_part(row.get(\"part\", None) or row.get(\"category\", None))\n",
        "\n",
        "        # temp_range: csv에 날씨 라벨이 있으면 맵핑, 없으면 넓게\n",
        "        wlab = normalize_str(row.get(\"날씨\", None))\n",
        "        temp_range = (-50, 50)\n",
        "        if wlab is not None:\n",
        "            # weather_map 키가 int/str 혼재 가능 -> 둘 다 시도\n",
        "            if wlab in WEATHER_LABEL_TO_TEMP_RANGE:\n",
        "                temp_range = tuple(WEATHER_LABEL_TO_TEMP_RANGE[wlab])\n",
        "            else:\n",
        "                try:\n",
        "                    wi = str(int(wlab))\n",
        "                    if wi in WEATHER_LABEL_TO_TEMP_RANGE:\n",
        "                        temp_range = tuple(WEATHER_LABEL_TO_TEMP_RANGE[wi])\n",
        "                except:\n",
        "                    pass\n",
        "        temp_range = safe_temp_range(temp_range)\n",
        "\n",
        "        metas.append({\"item_id\": iid, \"part\": part, \"temp_range\": temp_range})\n",
        "\n",
        "        for col in FEATURE_COLS:\n",
        "            m = maps[col]\n",
        "            v = normalize_str(row.get(col, None))\n",
        "            key = v if v is not None else \"<unk>\"\n",
        "            feats[col].append(m.get(key, 0))\n",
        "\n",
        "    feats_t = {col: torch.tensor(vals, dtype=torch.long) for col, vals in feats.items()}\n",
        "    z = item_enc(feats_t).cpu()  # (M,d)\n",
        "    return z, metas\n",
        "\n",
        "\n",
        "def merge_new_items_into_index(\n",
        "    item_embs: torch.Tensor,\n",
        "    item_metas: List[dict],\n",
        "    new_embs: torch.Tensor,\n",
        "    new_metas: List[dict],\n",
        "    overwrite_existing: bool = True\n",
        ") -> Tuple[torch.Tensor, List[dict], dict]:\n",
        "\n",
        "    id_to_idx = {get_item_id(m): i for i, m in enumerate(item_metas)}\n",
        "    replaced = 0\n",
        "    appended = 0\n",
        "    skipped = 0\n",
        "\n",
        "    # 교체는 텐서 in-place 가능\n",
        "    for e, m in zip(new_embs, new_metas):\n",
        "        iid = get_item_id(m)\n",
        "        if iid in id_to_idx:\n",
        "            if overwrite_existing:\n",
        "                idx = id_to_idx[iid]\n",
        "                item_metas[idx] = m\n",
        "                item_embs[idx] = e\n",
        "                replaced += 1\n",
        "            else:\n",
        "                skipped += 1\n",
        "        else:\n",
        "            item_metas.append(m)\n",
        "            item_embs = torch.cat([item_embs, e.unsqueeze(0)], dim=0).contiguous()\n",
        "            id_to_idx[iid] = len(item_metas) - 1\n",
        "            appended += 1\n",
        "\n",
        "    info = {\"replaced\": replaced, \"appended\": appended, \"skipped\": skipped, \"new_total\": len(item_metas)}\n",
        "    return item_embs, item_metas, info"
      ],
      "metadata": {
        "id": "K3FC3839vXTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시: 사용자 옷장 id 리스트 (여기에 넣으시면 됩니다)\n",
        "user_closet_ids = [\n",
        "    \"123\", \"456\", \"789\"\n",
        "]\n",
        "\n",
        "# 2번째 예시\n",
        "# closet_df = pd.read_csv(\"my_closet.csv\")  # 예: image_id 컬럼이 있음\n",
        "# user_closet_ids = closet_df[\"image_id\"].astype(str).tolist()"
      ],
      "metadata": {
        "id": "IR-wz2PyvYOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_topk_by_part_with_temp(\n",
        "    user_closet_ids: List[str],\n",
        "    query: str,\n",
        "    current_temp_text: str,\n",
        "    k: int = 5,\n",
        "    parts: Tuple[str, ...] = (\"상의\", \"하의\", \"아우터\", \"원피스\"),\n",
        "    temp_margin: int = 2,\n",
        "    print_scores: bool = True,\n",
        "):\n",
        "    current_temp = parse_temperature_to_int(current_temp_text)\n",
        "    closet = set(map(str, user_closet_ids))\n",
        "\n",
        "    # 1) 옷장 필터: 인덱스에서 closet에 있는 것만\n",
        "    idxs = []\n",
        "    metas = []\n",
        "    for i, m in enumerate(item_metas):\n",
        "        iid = get_item_id(m)\n",
        "        if iid in closet:\n",
        "            idxs.append(i)\n",
        "            # meta 정규화(특히 part/temp_range)\n",
        "            mm = dict(m)\n",
        "            mm[\"item_id\"] = iid\n",
        "            mm[\"part\"] = normalize_part(mm.get(\"part\", None) or mm.get(\"category\", None))\n",
        "            mm[\"temp_range\"] = safe_temp_range(mm.get(\"temp_range\", None))\n",
        "            metas.append(mm)\n",
        "\n",
        "    if len(idxs) == 0:\n",
        "        raise ValueError(\"옷장 item_id가 현재 인덱스(item_metas)에 하나도 없습니다. (id 키 이름/값 확인 필요)\")\n",
        "\n",
        "    embs = item_embs[idxs]  # (M,d)\n",
        "\n",
        "    # 2) 기온 필터\n",
        "    ok_mask = []\n",
        "    for mm in metas:\n",
        "        iid = mm[\"item_id\"]\n",
        "        # item_table_min이 있으면 우선\n",
        "        if iid in item_table_min:\n",
        "            tr = safe_temp_range(item_table_min[iid].get(\"temp_range\", None))\n",
        "            part_tbl = normalize_part(item_table_min[iid].get(\"part\", None))\n",
        "            if mm.get(\"part\") is None and part_tbl is not None:\n",
        "                mm[\"part\"] = part_tbl\n",
        "        else:\n",
        "            tr = safe_temp_range(mm.get(\"temp_range\", None))\n",
        "\n",
        "        mm[\"temp_range\"] = tr\n",
        "        tmin, tmax = tr\n",
        "        ok = (tmin - temp_margin) <= current_temp <= (tmax + temp_margin)\n",
        "        ok_mask.append(ok)\n",
        "\n",
        "    ok_mask = torch.tensor(ok_mask, dtype=torch.bool)\n",
        "\n",
        "    # 3) 텍스트 임베딩\n",
        "    zt = encode_text(query)               # (1,d)\n",
        "    sims = (zt @ embs.T).squeeze(0)       # (M,)\n",
        "\n",
        "    if print_scores:\n",
        "        print(\"=\" * 90)\n",
        "        print(f\"query: {query}\")\n",
        "        print(f\"temp: {current_temp_text} -> {current_temp}°C (margin={temp_margin})\")\n",
        "        print(f\"closet size: {len(metas)} | after temp filter: {int(ok_mask.sum().item())}\")\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "    results = {}\n",
        "    for part in parts:\n",
        "        part_mask = torch.tensor([mm.get(\"part\") == part for mm in metas], dtype=torch.bool)\n",
        "        mask = ok_mask & part_mask\n",
        "\n",
        "        if int(mask.sum().item()) == 0:\n",
        "            results[part] = []\n",
        "            if print_scores:\n",
        "                print(f\"[{part}] no candidates\")\n",
        "            continue\n",
        "\n",
        "        sims_f = sims.clone()\n",
        "        sims_f[~mask] = -1e9\n",
        "        topv, topi = torch.topk(sims_f, k=min(k, int(mask.sum().item())))\n",
        "\n",
        "        rows = []\n",
        "        if print_scores:\n",
        "            print(f\"\\n[{part}] top-{len(topi)}\")\n",
        "\n",
        "        for rank, (score, li) in enumerate(zip(topv.tolist(), topi.tolist()), 1):\n",
        "            iid = metas[li][\"item_id\"]\n",
        "            tr = metas[li][\"temp_range\"]\n",
        "            rows.append({\"item_id\": iid, \"score\": float(score), \"temp_range\": tr, \"part\": part})\n",
        "            if print_scores:\n",
        "                print(f\"  {rank:>2}. {iid}  score={score:.4f}  temp={tr[0]}~{tr[1]}\")\n",
        "\n",
        "        results[part] = rows\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "q0KRzNjTveXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"캐주얼한 주말 카페룩\"\n",
        "current_temp_text = \"8도\"  # API에서 들어온 기온 텍스트(예: \"영하 3도\", \"-2\", \"5°C\" 등도 가능)\n",
        "\n",
        "res = recommend_topk_by_part_with_temp(\n",
        "    user_closet_ids=user_closet_ids,\n",
        "    query=query,\n",
        "    current_temp_text=current_temp_text,\n",
        "    k=5,\n",
        "    parts=(\"상의\", \"하의\", \"아우터\", \"원피스\"),\n",
        "    temp_margin=2,\n",
        "    print_scores=True,\n",
        ")\n",
        "res"
      ],
      "metadata": {
        "id": "cmRLV0BFvhvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신규 옷 CSV 들어왔을 때: 임베딩 + 인덱스 갱신\n",
        "new_df = pd.read_csv(\"new_items.csv\")  # 신규 정형화 아이템 데이터\n",
        "new_embs, new_metas = encode_items_from_df(new_df, id_col=\"image_id\")\n",
        "item_embs, item_metas, info = merge_new_items_into_index(item_embs, item_metas, new_embs, new_metas, overwrite_existing=True)\n",
        "print(info)"
      ],
      "metadata": {
        "id": "kaANrnyjvkp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}